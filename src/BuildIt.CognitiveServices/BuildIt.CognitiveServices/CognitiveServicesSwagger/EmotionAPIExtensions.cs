// Code generated by Microsoft (R) AutoRest Code Generator 0.17.0.0
// Changes may cause incorrect behavior and will be lost if the code is
// regenerated.

namespace BuildIt.CognitiveServices
{
    using System.Threading.Tasks;

    /// <summary>
    /// Extension methods for EmotionAPI.
    /// </summary>
    public static partial class EmotionAPIExtensions
    {
            /// <summary>
            /// &lt;p&gt;Recognizes the emotions expressed by one or more people in an
            /// image, as well as returns a bounding box for the face. The emotions
            /// detected are happiness, sadness, surprise, anger, fear, contempt, and
            /// disgust or neutral. &lt;br/&gt;&amp;bull; The supported input image
            /// formats includes JPEG, PNG, GIF(the first frame), BMP. Image file size
            /// should be no larger than 4MB. &lt;br/&gt;&amp;bull; If a user has already
            /// called the Face API, they can submit the face rectangles as an optional
            /// input. Otherwise, Emotion API will first compute the rectangles.
            /// &lt;br/&gt;&amp;bull; The detectable face size range is 36x36 to
            /// 4096x4096 pixels. Faces out of this range will not be detected.
            /// &lt;br/&gt;&amp;bull; For each image, the maximum number of faces
            /// detected is 64 and the faces are ranked by face rectangle size in
            /// descending order. If no face is detected, an empty array will be
            /// returned. &lt;br/&gt;&amp;bull; Some faces may not be detected due to
            /// technical challenges, e.g. very large face angles (head-pose), large
            /// occlusion. Frontal and near-frontal faces have the best results.
            /// &lt;br/&gt;&amp;bull; The emotions contempt and disgust are
            /// experimental.&lt;/p&gt;
            /// </summary>
            /// <param name='operations'>
            /// The operations group for this extension method.
            /// </param>
            /// <param name='subscriptionKey'>
            /// subscription key in url
            /// </param>
            /// <param name='ocpApimSubscriptionKey'>
            /// subscription key in header
            /// </param>
            public static void EmotionRecognition(this IEmotionAPI operations, string subscriptionKey = default(string), string ocpApimSubscriptionKey = default(string))
            {
                System.Threading.Tasks.Task.Factory.StartNew(s => ((IEmotionAPI)s).EmotionRecognitionAsync(subscriptionKey, ocpApimSubscriptionKey), operations, System.Threading.CancellationToken.None, System.Threading.Tasks.TaskCreationOptions.None,  System.Threading.Tasks.TaskScheduler.Default).Unwrap().GetAwaiter().GetResult();
            }

            /// <summary>
            /// &lt;p&gt;Recognizes the emotions expressed by one or more people in an
            /// image, as well as returns a bounding box for the face. The emotions
            /// detected are happiness, sadness, surprise, anger, fear, contempt, and
            /// disgust or neutral. &lt;br/&gt;&amp;bull; The supported input image
            /// formats includes JPEG, PNG, GIF(the first frame), BMP. Image file size
            /// should be no larger than 4MB. &lt;br/&gt;&amp;bull; If a user has already
            /// called the Face API, they can submit the face rectangles as an optional
            /// input. Otherwise, Emotion API will first compute the rectangles.
            /// &lt;br/&gt;&amp;bull; The detectable face size range is 36x36 to
            /// 4096x4096 pixels. Faces out of this range will not be detected.
            /// &lt;br/&gt;&amp;bull; For each image, the maximum number of faces
            /// detected is 64 and the faces are ranked by face rectangle size in
            /// descending order. If no face is detected, an empty array will be
            /// returned. &lt;br/&gt;&amp;bull; Some faces may not be detected due to
            /// technical challenges, e.g. very large face angles (head-pose), large
            /// occlusion. Frontal and near-frontal faces have the best results.
            /// &lt;br/&gt;&amp;bull; The emotions contempt and disgust are
            /// experimental.&lt;/p&gt;
            /// </summary>
            /// <param name='operations'>
            /// The operations group for this extension method.
            /// </param>
            /// <param name='subscriptionKey'>
            /// subscription key in url
            /// </param>
            /// <param name='ocpApimSubscriptionKey'>
            /// subscription key in header
            /// </param>
            /// <param name='cancellationToken'>
            /// The cancellation token.
            /// </param>
            public static async System.Threading.Tasks.Task EmotionRecognitionAsync(this IEmotionAPI operations, string subscriptionKey = default(string), string ocpApimSubscriptionKey = default(string), System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
            {
                await operations.EmotionRecognitionWithHttpMessagesAsync(subscriptionKey, ocpApimSubscriptionKey, null, cancellationToken).ConfigureAwait(false);
            }

            /// <summary>
            /// &lt;p&gt;Welcome to the Microsoft Emotion API for Video. Emotion API for
            /// Video is a cloud-based API that recognizes the emotions expressed by the
            /// people in an image and returns their emotions. The emotions detected are
            /// happiness, sadness, surprise, anger, fear, contempt, and disgust or
            /// neutral. These APIs allow you to build more personalized and intelligent
            /// apps by understanding your video content. &lt;/p&gt;
            /// &lt;br/&gt;
            /// Emotion Recognition&lt;br/&gt;
            /// Returns aggregate emotions for the faces in a video.&lt;br/&gt;
            /// &amp;bull; The supported input video formats include MP4, MOV, and WMV.
            /// Video file size should be no larger than 100MB. &lt;br/&gt;
            /// &amp;bull; The detectable face size range is 24x24 to 2048x2048 pixels.
            /// The faces out of this range will not be detected. &lt;br/&gt;
            /// &amp;bull; For each video, the maximum number of faces returned is 64.
            /// &lt;br/&gt;
            /// &amp;bull; Some faces may not be detected due to technical challenges;
            /// e.g. very large face angles (head-pose), and large occlusion. Frontal and
            /// near-frontal faces have the best results. &lt;br/&gt;
            /// &amp;bull; Output files are deleted after 24 hours. &lt;br/&gt;
            /// </summary>
            /// <param name='operations'>
            /// The operations group for this extension method.
            /// </param>
            /// <param name='outputStyle'>
            /// Defaults to “aggregate” style, but a user can specify “perFrame” style.
            /// Possible values include: 'aggregate', 'perFrame'
            /// </param>
            /// <param name='subscriptionKey'>
            /// subscription key in url
            /// </param>
            /// <param name='ocpApimSubscriptionKey'>
            /// subscription key in header
            /// </param>
            public static void EmotionRecognitioninVideo(this IEmotionAPI operations, string outputStyle = "aggregate", string subscriptionKey = default(string), string ocpApimSubscriptionKey = default(string))
            {
                System.Threading.Tasks.Task.Factory.StartNew(s => ((IEmotionAPI)s).EmotionRecognitioninVideoAsync(outputStyle, subscriptionKey, ocpApimSubscriptionKey), operations, System.Threading.CancellationToken.None, System.Threading.Tasks.TaskCreationOptions.None,  System.Threading.Tasks.TaskScheduler.Default).Unwrap().GetAwaiter().GetResult();
            }

            /// <summary>
            /// &lt;p&gt;Welcome to the Microsoft Emotion API for Video. Emotion API for
            /// Video is a cloud-based API that recognizes the emotions expressed by the
            /// people in an image and returns their emotions. The emotions detected are
            /// happiness, sadness, surprise, anger, fear, contempt, and disgust or
            /// neutral. These APIs allow you to build more personalized and intelligent
            /// apps by understanding your video content. &lt;/p&gt;
            /// &lt;br/&gt;
            /// Emotion Recognition&lt;br/&gt;
            /// Returns aggregate emotions for the faces in a video.&lt;br/&gt;
            /// &amp;bull; The supported input video formats include MP4, MOV, and WMV.
            /// Video file size should be no larger than 100MB. &lt;br/&gt;
            /// &amp;bull; The detectable face size range is 24x24 to 2048x2048 pixels.
            /// The faces out of this range will not be detected. &lt;br/&gt;
            /// &amp;bull; For each video, the maximum number of faces returned is 64.
            /// &lt;br/&gt;
            /// &amp;bull; Some faces may not be detected due to technical challenges;
            /// e.g. very large face angles (head-pose), and large occlusion. Frontal and
            /// near-frontal faces have the best results. &lt;br/&gt;
            /// &amp;bull; Output files are deleted after 24 hours. &lt;br/&gt;
            /// </summary>
            /// <param name='operations'>
            /// The operations group for this extension method.
            /// </param>
            /// <param name='outputStyle'>
            /// Defaults to “aggregate” style, but a user can specify “perFrame” style.
            /// Possible values include: 'aggregate', 'perFrame'
            /// </param>
            /// <param name='subscriptionKey'>
            /// subscription key in url
            /// </param>
            /// <param name='ocpApimSubscriptionKey'>
            /// subscription key in header
            /// </param>
            /// <param name='cancellationToken'>
            /// The cancellation token.
            /// </param>
            public static async System.Threading.Tasks.Task EmotionRecognitioninVideoAsync(this IEmotionAPI operations, string outputStyle = "aggregate", string subscriptionKey = default(string), string ocpApimSubscriptionKey = default(string), System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
            {
                await operations.EmotionRecognitioninVideoWithHttpMessagesAsync(outputStyle, subscriptionKey, ocpApimSubscriptionKey, null, cancellationToken).ConfigureAwait(false);
            }

            /// <summary>
            /// Get operation result. If succeeded, this interface returns a JSON that
            /// includes time stamps and operation status/result. Below is an example:
            /// &lt;br/&gt;
            /// 
            /// Example JSON:
            /// &lt;table class="element table"&gt;
            /// &lt;thead&gt;
            /// &lt;/thead&gt;
            /// &lt;tbody&gt;
            /// &lt;tr&gt;
            /// {&lt;br/&gt;
            /// "status": "Running",&lt;br/&gt;
            /// "createdDateTime":  "2015-09-30T01:28:23.4493273Z",&lt;br/&gt;
            /// "lastActionDateTime": "2015-09-30T01:32:23.0895791Z",&lt;br/&gt;
            /// }&lt;br/&gt;
            /// &lt;/tr&gt;
            /// &lt;/tbody&gt;
            /// &lt;/table&gt;
            /// &lt;br/&gt;
            /// &lt;p&gt;
            /// Possible values of "status" field are:&lt;br/&gt;
            /// &lt;b&gt;Not Started&lt;/b&gt; - video content is received/uploaded but
            /// the process has not started.&lt;br/&gt;
            /// &lt;b&gt;Uploading&lt;/b&gt; - the video content is being uploaded by the
            /// URL client side provides.&lt;br/&gt;
            /// &lt;b&gt;Running&lt;/b&gt; - the process is running.&lt;br/&gt;
            /// &lt;b&gt;Failed&lt;/b&gt; - the process is failed. Detailed information
            /// will be provided in "message" field.&lt;br/&gt;
            /// &lt;b&gt;Succeeded&lt;/b&gt; - the process succeeded. In this case,
            /// depending on specific operation client side created, the result can be
            /// retrieved in following two ways:&lt;br/&gt;
            /// &lt;/p&gt;
            /// The result (as a JSON in string) is available in
            /// &lt;b&gt;processingResult&lt;/b&gt; field.
            /// </summary>
            /// <param name='operations'>
            /// The operations group for this extension method.
            /// </param>
            /// <param name='oid'>
            /// </param>
            /// <param name='subscriptionKey'>
            /// subscription key in url
            /// </param>
            /// <param name='ocpApimSubscriptionKey'>
            /// subscription key in header
            /// </param>
            public static void GetRecognitioninVideoOperationResult(this IEmotionAPI operations, string oid, string subscriptionKey = default(string), string ocpApimSubscriptionKey = default(string))
            {
                System.Threading.Tasks.Task.Factory.StartNew(s => ((IEmotionAPI)s).GetRecognitioninVideoOperationResultAsync(oid, subscriptionKey, ocpApimSubscriptionKey), operations, System.Threading.CancellationToken.None, System.Threading.Tasks.TaskCreationOptions.None,  System.Threading.Tasks.TaskScheduler.Default).Unwrap().GetAwaiter().GetResult();
            }

            /// <summary>
            /// Get operation result. If succeeded, this interface returns a JSON that
            /// includes time stamps and operation status/result. Below is an example:
            /// &lt;br/&gt;
            /// 
            /// Example JSON:
            /// &lt;table class="element table"&gt;
            /// &lt;thead&gt;
            /// &lt;/thead&gt;
            /// &lt;tbody&gt;
            /// &lt;tr&gt;
            /// {&lt;br/&gt;
            /// "status": "Running",&lt;br/&gt;
            /// "createdDateTime":  "2015-09-30T01:28:23.4493273Z",&lt;br/&gt;
            /// "lastActionDateTime": "2015-09-30T01:32:23.0895791Z",&lt;br/&gt;
            /// }&lt;br/&gt;
            /// &lt;/tr&gt;
            /// &lt;/tbody&gt;
            /// &lt;/table&gt;
            /// &lt;br/&gt;
            /// &lt;p&gt;
            /// Possible values of "status" field are:&lt;br/&gt;
            /// &lt;b&gt;Not Started&lt;/b&gt; - video content is received/uploaded but
            /// the process has not started.&lt;br/&gt;
            /// &lt;b&gt;Uploading&lt;/b&gt; - the video content is being uploaded by the
            /// URL client side provides.&lt;br/&gt;
            /// &lt;b&gt;Running&lt;/b&gt; - the process is running.&lt;br/&gt;
            /// &lt;b&gt;Failed&lt;/b&gt; - the process is failed. Detailed information
            /// will be provided in "message" field.&lt;br/&gt;
            /// &lt;b&gt;Succeeded&lt;/b&gt; - the process succeeded. In this case,
            /// depending on specific operation client side created, the result can be
            /// retrieved in following two ways:&lt;br/&gt;
            /// &lt;/p&gt;
            /// The result (as a JSON in string) is available in
            /// &lt;b&gt;processingResult&lt;/b&gt; field.
            /// </summary>
            /// <param name='operations'>
            /// The operations group for this extension method.
            /// </param>
            /// <param name='oid'>
            /// </param>
            /// <param name='subscriptionKey'>
            /// subscription key in url
            /// </param>
            /// <param name='ocpApimSubscriptionKey'>
            /// subscription key in header
            /// </param>
            /// <param name='cancellationToken'>
            /// The cancellation token.
            /// </param>
            public static async System.Threading.Tasks.Task GetRecognitioninVideoOperationResultAsync(this IEmotionAPI operations, string oid, string subscriptionKey = default(string), string ocpApimSubscriptionKey = default(string), System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
            {
                await operations.GetRecognitioninVideoOperationResultWithHttpMessagesAsync(oid, subscriptionKey, ocpApimSubscriptionKey, null, cancellationToken).ConfigureAwait(false);
            }

            /// <summary>
            /// &lt;p&gt;Recognizes the emotions expressed by one or more people in an
            /// image, as well as returns a bounding box for the face. The emotions
            /// detected are happiness, sadness, surprise, anger, fear, contempt, and
            /// disgust or neutral. &lt;br/&gt;&amp;bull; The supported input image
            /// formats includes JPEG, PNG, GIF(the first frame), BMP. Image file size
            /// should be no larger than 4MB. &lt;br/&gt;&amp;bull; If a user has already
            /// called the Face API, they can submit the face rectangles as an optional
            /// input. Otherwise, Emotion API will first compute the rectangles.
            /// &lt;br/&gt;&amp;bull; The detectable face size range is 36x36 to
            /// 4096x4096 pixels. Faces out of this range will not be detected.
            /// &lt;br/&gt;&amp;bull; For each image, the maximum number of faces
            /// detected is 64 and the faces are ranked by face rectangle size in
            /// descending order. If no face is detected, an empty array will be
            /// returned. &lt;br/&gt;&amp;bull; Some faces may not be detected due to
            /// technical challenges, e.g. very large face angles (head-pose), large
            /// occlusion. Frontal and near-frontal faces have the best results.
            /// &lt;br/&gt;&amp;bull; The emotions contempt and disgust are
            /// experimental.&lt;/p&gt;
            /// </summary>
            /// <param name='operations'>
            /// The operations group for this extension method.
            /// </param>
            /// <param name='faceRectangles'>
            /// A face rectangle is in the form “left,top,width,height”. Delimited
            /// multiple face rectangles with a “;”.
            /// </param>
            /// <param name='subscriptionKey'>
            /// subscription key in url
            /// </param>
            /// <param name='ocpApimSubscriptionKey'>
            /// subscription key in header
            /// </param>
            public static void EmotionRecognitionwithFaceRectangles(this IEmotionAPI operations, string faceRectangles, string subscriptionKey = default(string), string ocpApimSubscriptionKey = default(string))
            {
                System.Threading.Tasks.Task.Factory.StartNew(s => ((IEmotionAPI)s).EmotionRecognitionwithFaceRectanglesAsync(faceRectangles, subscriptionKey, ocpApimSubscriptionKey), operations, System.Threading.CancellationToken.None, System.Threading.Tasks.TaskCreationOptions.None,  System.Threading.Tasks.TaskScheduler.Default).Unwrap().GetAwaiter().GetResult();
            }

            /// <summary>
            /// &lt;p&gt;Recognizes the emotions expressed by one or more people in an
            /// image, as well as returns a bounding box for the face. The emotions
            /// detected are happiness, sadness, surprise, anger, fear, contempt, and
            /// disgust or neutral. &lt;br/&gt;&amp;bull; The supported input image
            /// formats includes JPEG, PNG, GIF(the first frame), BMP. Image file size
            /// should be no larger than 4MB. &lt;br/&gt;&amp;bull; If a user has already
            /// called the Face API, they can submit the face rectangles as an optional
            /// input. Otherwise, Emotion API will first compute the rectangles.
            /// &lt;br/&gt;&amp;bull; The detectable face size range is 36x36 to
            /// 4096x4096 pixels. Faces out of this range will not be detected.
            /// &lt;br/&gt;&amp;bull; For each image, the maximum number of faces
            /// detected is 64 and the faces are ranked by face rectangle size in
            /// descending order. If no face is detected, an empty array will be
            /// returned. &lt;br/&gt;&amp;bull; Some faces may not be detected due to
            /// technical challenges, e.g. very large face angles (head-pose), large
            /// occlusion. Frontal and near-frontal faces have the best results.
            /// &lt;br/&gt;&amp;bull; The emotions contempt and disgust are
            /// experimental.&lt;/p&gt;
            /// </summary>
            /// <param name='operations'>
            /// The operations group for this extension method.
            /// </param>
            /// <param name='faceRectangles'>
            /// A face rectangle is in the form “left,top,width,height”. Delimited
            /// multiple face rectangles with a “;”.
            /// </param>
            /// <param name='subscriptionKey'>
            /// subscription key in url
            /// </param>
            /// <param name='ocpApimSubscriptionKey'>
            /// subscription key in header
            /// </param>
            /// <param name='cancellationToken'>
            /// The cancellation token.
            /// </param>
            public static async System.Threading.Tasks.Task EmotionRecognitionwithFaceRectanglesAsync(this IEmotionAPI operations, string faceRectangles, string subscriptionKey = default(string), string ocpApimSubscriptionKey = default(string), System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
            {
                await operations.EmotionRecognitionwithFaceRectanglesWithHttpMessagesAsync(faceRectangles, subscriptionKey, ocpApimSubscriptionKey, null, cancellationToken).ConfigureAwait(false);
            }

    }
}
